# docker/config/spark/spark-defaults.conf

# Spark SQL Configuration
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.skewJoin.enabled=true

# Memory Configuration
spark.executor.memory=2g
spark.driver.memory=1g
spark.executor.memoryFraction=0.8
spark.executor.cores=2

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer

# Dynamic Allocation
spark.dynamicAllocation.enabled=false
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.maxExecutors=3
spark.dynamicAllocation.initialExecutors=1

# Kafka Configuration
spark.sql.streaming.checkpointLocation=/opt/spark/checkpoints

# MongoDB Configuration
spark.mongodb.input.uri=mongodb://admin:admin123@mongodb:27017/weather_db
spark.mongodb.output.uri=mongodb://admin:admin123@mongodb:27017/weather_db

# PostgreSQL Configuration
spark.sql.warehouse.dir=/opt/spark/warehouse

# Logging
spark.eventLog.enabled=true
spark.eventLog.dir=/opt/spark/logs
spark.history.fs.logDirectory=/opt/spark/logs

# Network
spark.driver.host=spark-master
spark.driver.bindAddress=0.0.0.0